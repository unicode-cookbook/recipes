{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment graphemes in IPA text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steven Moran &lt;bambooforest@gmail.com&gt;\n",
    "\n",
    "The latest version of this [Jupyter notebook](http://jupyter.org/) is available at [https://github.com/unicode-cookbook/recipes/JIPA](https://github.com/unicode-cookbook/recipes/JIPA). \n",
    "\n",
    "This use case illustrates how to segment wordlist data using an orthography profile. Details about orthography profiles and more is available in the [Unicode Cookbook for Linguists](https://github.com/unicode-cookbook/cookbook).\n",
    "\n",
    "This recipes uses Python 3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This use case illustrates how to segment graphemes in IPA text.\n",
    "\n",
    "The [https://www.internationalphoneticassociation.org/content/full-ipa-chart](International Phonetic Alphabet) is a standardized system of phonetic notation often used by linguists to transcribe phonological data.\n",
    "\n",
    "This recipe requires some text in IPA, so we typed up a few transcriptions of the [https://en.wikipedia.org/wiki/The_North_Wind_and_the_Sun](North Wind and the Sun passage) from the excellent series, Illustrations of the IPA in the [https://www.cambridge.org/core/journals/journal-of-the-international-phonetic-association](Journal of the International Phonetic Association). These short articles illustrate the use of IPA transcription. The series is comprised of over 100 hundred richly detailed phonological descriptions from languages from around the world. Kenneth S. Olson provides a [http://www-01.sil.org/~olsonk/ipa.html](useful list of the articles) with additional metadata (ISO 639-3 codes and references).\n",
    "\n",
    "These fine illustrations present a broad set of orthographic challenges, including tone, stress, diphthongs, and diacritics:\n",
    "\n",
    "- Brazilian Portuguese (ISO 639-3: por) by Barbosa, Plínio A. & Eleonora C. Albano. 2004. JIPA 34(2). 227–232.\n",
    "- Kabiye (kbp) by Padayodi, Cécile M. 2008. JIPA 38(2). 215–221.\n",
    "- Vietnamese (vie) by Kirby, J.P. 2011. JIPA 41(3). 381–392.\n",
    "- Zurich German (gsw) by Fleischer, Jürg & Stephan Schmid. 2006. JIPA 36(2). 243–253.\n",
    "\n",
    "These files can be found in the `sources` folder. For each passage, there are two files, one suffixed with `_input` and the other with `_output`. Input files are the raw text where words are separated by white space. The corresponding ouput files have been been grapheme segmented by hand. Each grapheme is separated by white space and each word by the boundary marker `#`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the files in the `sources` directory. Use `more` or `less` or `cat` on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "u vẽⁿtʊ nɔɾt͡ʃɪ̥ u sɔʊ̯ dʲiskut͡ʃiɐ̃ʊ̯ kʊ̯aʊ̯ duz doɪ̯z ɛɾɐ u maɪ̯s fɔɾt͡ʃɪ̥ | kʊ̯ɐ̃ⁿdʊ suseˈd \beʊ̯ paˈsaɾ ũ viaʒɐ̃ⁿt͡ʃɪ̃voʊ̯tʊ ˈnũma kapɐ ‖ aʊ̯ velʊ põɪ̯sɪ d͡ʒɪ̯akoɾdʊ ɪ̯̃ kõmakelɪ kɪ pɾ \bimeɾʊ kõsɪˈgis̩ obɾiˈgaɾ u vɪaʒɐ̃ⁿt͡ʃɪ̯ɐt͡ʃiˈɾaɾ a kapɐ seɾiɐ kõs̩deˈɾadu maɪ̯s fɔɾt͡ʃɪ̥  \b‖ u vẽⁿtʊ nɔɾɪ̥ komeˈsoɐ̯ soˈpɾaɾ kõ ˈmũɪ̯̃ta fuɾɪ̯ɐ | mas kʊ̯ɐ̃ⁿtʊ maɪ̯sopɾavɐ maɪ̯z u v \bɪaˈʒɐ̃ⁿt sɪ̯akõʃeˈgava suɐ kapɐ̰ | aˈtɛ kɪ̯ʊ vẽⁿtʊ nɔɾt͡ʃɪ dʲizisˈt͡ʃiʊ̯ ‖ u sɔʊ̯ bɾiˈʎo \bʊ̯ tevɪ̯aˈsɪ̃ dʲi ɣekõɲeˈseɾ a supeɾioɾidadʲɪ du sɔʊ̯\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "!more sources/Brazilian_Portuguese_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "u # v ẽⁿ t ʊ # n ɔ ɾ t͡ʃ ɪ̥ # u # s ɔ ʊ̯ # dʲ i s k u t͡ʃ i ɐ̃ ʊ̯ # k ʊ̯ a ʊ̯ # d u z #  \bd o ɪ̯ z # ɛ ɾ ɐ # u # m a ɪ̯ s # f ɔ ɾ t͡ʃ ɪ̥ # | # k ʊ̯ ɐ̃ⁿ d ʊ # s u s e ˈd e ʊ̯ # p \b a ˈs a ɾ # ũ # v i a ʒ ɐ̃ⁿ t͡ʃ ɪ̃ v o ʊ̯ t ʊ # ˈn ũ m a # k a p ɐ # ‖ # a ʊ̯ # v e l \b ʊ # p õ ɪ̯ s ɪ # d͡ʒ ɪ̯ a k o ɾ d ʊ # ɪ̯̃ # k õ m a k e l ɪ # k ɪ # p ɾ i m e ɾ ʊ #  \bk õ s ɪ ˈg i s̩ # o b ɾ i ˈg a ɾ # u # v ɪ a ʒ ɐ̃ⁿ t͡ʃ ɪ̯ ɐ t͡ʃ i ˈɾ a ɾ # a # k a p  \bɐ # s e ɾ i ɐ # k õ s̩ d e ˈɾ a d u # m a ɪ̯ s # f ɔ ɾ t͡ʃ ɪ̥ # ‖ # u # v ẽⁿ t ʊ # n \b ɔ ɾ ɪ̥ # k o m e ˈs o ɐ̯ # s o ˈp ɾ a ɾ # k õ # ˈm ũ ɪ̯̃ t a # f u ɾ ɪ̯ ɐ # | # m a  \bs # k ʊ̯ ɐ̃ⁿ t ʊ # m a ɪ̯ s o p ɾ a v ɐ # m a ɪ̯ z # u # v ɪ a ˈʒ ɐ̃ⁿ t # s ɪ̯ a k õ ʃ \b e ˈg a v a # s u ɐ # k a p ɐ̰ # | # a ˈt ɛ # k ɪ̯ ʊ # v ẽⁿ t ʊ # n ɔ ɾ t͡ʃ ɪ # dʲ  \bi z i s ˈt͡ʃ i ʊ̯ # ‖ # u # s ɔ ʊ̯ # b ɾ i ˈʎ o ʊ̯ # t e v ɪ̯ a ˈs ɪ̃ # dʲ i # ɣ e k õ \b ɲ e ˈs e ɾ # a # s u p e ɾ i o ɾ i d a dʲ ɪ # d u # s ɔ ʊ̯\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "! more sources/Brazilian_Portuguese_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "hà̙jìkíŋ́ hèˠèˠlím̀ nɛ̙̀ wí̙sì̙ hà̙jìkíŋ́ hèˠèˠlím̀ nɛ̙̀ wɪ̙́sɪ̙̀ bà̙à̙ mà̙ˠà̙ˠzɪ̙́nɪ̙́ ḿbʊ̙́ zɪ̙̀ bà̙nà̙ zɪ̙́ á̙ \bkɪ̙́lɪ̙́ ɖóŋ̀ ‖ pɪ̙̀ɡɛ̙̀dá̙à̙ lɛ̙́ | nʊ̙́mɔ̙̀wòɽú nɔ̙́ɔ̙́jʊ̙̀ ɖɛ̙̀wà̙ˠá̙ˠ | ɛ̙̀hɔ̙̀kɪ̙́ ɛ̙̀dɪ̙̀ɪ̙̀ dókò ɡ͡bìŋ̀ɡìzìm ɲɪ̙́ŋ́ɡʊ̙̀ \b nà̙kʊ̙́jʊ̙̀ dà̙á̙ ‖ pá̙nɪ̙́ɪ̙́ná̙ ɖá̙má̙ zɪ̙̀ wèjí ɛ̙́ɽá̙ bɪ̙́zʊ̙́ʊ̙́ ɛ̙́lá̙ nʊ̙́mɔ̙̀wòɽú ɛ̙́nʊ̙́ ɛ̙́hɔ̙́zɪ̙̀ òdókòò lɛ̙́ |  \bɛ̙́nʊ̙́ ɡɪ̙́lɪ̙́ná̙ ɖóŋ̀ ‖ kɛ̙́lɛ̙́ | hà̙jìkíŋ́ hèˠèˠlíḿ bá̙zɪ̙́ bɪ̙́má̙ ɖéŋ́ɖéé bɪ̙́bɪ̙́zɪ̙̀ˠɪ̙̀ˠ jɔ̙́ ‖ kɔ̙́jɔ̙́ bɪ̙̀ \bmá̙kɪ̙́ ɖóŋ̀ lɛ̙́ | nʊ̙́mɔ̙̀wòɽú ɲí ɡ͡bííkíˠíˠ ɛ̙̀dɪ̙̀ɪ̙̀ òdókò dà̙à̙ ɡíɡ͡bììkú ‖ pɪ̙́nɪ̙́ɪ̙́ hà̙jìkíŋ́ hèˠè \bˠlím̀ nɛ̙̀ bɪ̙́tɛ̙́↓zɪ̙́ ↓jébù ‖ kɛ̙́lɛ̙́ wɪ̙́↓sɪ̙́ɲá̙ sɪ̙́ŋ́↓ɡɪ̙́ ↓zɪ̙́ɲá̙ˠá̙ˠ ɖéŋ́↓ ɖéé ↓zɪ̙́bɪ̙́zɪ̙̀ˠɪ̙̀ˠjɔ̙́ kà̙ʊ̙̀ʊ̙̀ʊ̙̀ \b ‖ nʊ̙́mɔ̙̀wòɽú dɪ̙́ ↓hɔ̙́zʊ̙́ ↓édókó ↓ɛ̙́lɔ̙́ ‖ pèéɽèè bɪ̙́ɽɛ̙́ hà̙jìkíŋ́ hèˠèˠlím̀ nɪ̙̀ bídísì zɪ̙̀ bà̙d \bà̙á̙ lɛ̙́ | wí̙sì̙ ɡɪ̙̀lɪ̙́↓ná̙ ɖóŋ̀ nòòò ‖\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "!more sources/Kabiye_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "zɔ˩˨ ɓɤ̆k˦˥ va˧˨ măt˨˩ tɕɤj˧˨ kaj˧˨˦ ɲaw˦ sɛm˦ aj˦ mɛŋ̟˨ hɤn˦ tɕɔŋ͡m˦ luk͡p˦˥ ɗɔ˧˦ m \bot˨˩ zu˦ xɛk˦˥ măk˨˩ mot˨˩ aw˧˦ xʷak˦˥ ɤm˨˦ ɗi˦ kʷa˦ hɔ˨ zaw˦ kɛw˧˨ vɤj˧˦ ɲaw˦ z \băŋ˧˨ ʔaj˦ la˧˨ ŋɯəj˧˨ ɗɤ̆w˧˨ tiən˦ ma˧˨ kɔ˨˧ tʰe˧˩˨ ɓăt˦˥ ŋɯəj˧˨ zu˦ xɛk˦˥ kiə˦ k \bɤj˧˩˨ ʔaw˧˦ tʰi˧˨ sɛ˧˨˥ ɗɯək˨˩ kɔj˦ la˧˨ mɛŋ̟˨ hɤn˦ săw˦ ɗɔ˨˦ zɔ˨˦ ɓɤ̆k˦˥ ɓăt˦˥ dɤ̆ \bw˧˨ tʰoj˧˩˨ mɛŋ̟˨ het˦˥ sɯk˦˥ kɔ˨˦ tʰe˧˩˨ ɲɯŋ˦ kaŋ˧˨ tʰoj˧˩˨ tʰi˧˨ ŋɯəj˧˨ zu˦ xɛk \b˦˥ kaŋ˧˨ zɯ˧˨˦ tɕăt˨˩ ʔaw˧˦ xʷak˦˥ va˧˨ kuj˧˦ kuŋ͡m˧˨ zɔ˧˦ ɓɤ̆k˦˥ ɗa˧˨˦ faj˧˩˨ tɯ˧ \b˨ ɓɔ˧˩˨ săw˦ ɗɔ˨˧ măt˨˩ tɕɤj˧˨ sɯəj˧˩˨ ʔɤ̆m˨˧ va˧˨ ŋɯəj˧˨ zu˦ xek˦˥ lien˧˨ kɤj˧˩˨ \b ʔaw˨˧ xʷak˦˥ ket˦˥ kuk͡p˨˩ la˧˨ zɔ˧˦ ɓɤ̆k˦˥ faj˧˩˨ tʰɯə˧˨ ɲɤ̆n˨ zăŋ˧˨ măt˨˩ tɕɤj˦˧ \b la˧˨ ŋɯəj˧˨ mɛŋ̟˨ hɤn˦ tɕɔŋ͡m˦ haj˦ ŋɯəj˧˨\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "!more sources/Vietnamese_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\r",
      "d̥ə ˈb̥iːz̥ˌʋi̞nd̥ u̞n‿ˈt͡su̞nə ‖ əˈmɒːl hæn‿tə ˈb̥iːz̥ˌʋi̞nd̥ u̞n‿ˈt͡su̞nə ˈkʃtri̞tːə | ʋɛːr v̥o \b ˈb̥æi̯ʔnə d̥ɒz̥ æχ tə ˈʃtɛrɣ̥ər z̥ei̯ɡ̥ ‖ d̥ɒ ʁ̥u̞nt ə‿ˈmːɒː d̥ətˈhɛːʁ | ʋon ən ˈtːi̞k͡χə ˈmɒ \bntl̩ ˈɒːkhɒ hæt̚ ‖ d̥o z̥i̞nt͡s ˈrœːtːi̞ɡ̥ ˈʋoːrd̥ə | d̥ɒs ˈtɛː d̥ə ˈʃtɛrɣ̥ər z̥ei̯ɡ | ʋo d̥ɛː  \bmɒː d̥əˈt͡su̞ə̯ ˈb̥ri̞ŋi̞ | d̥ɒz̥ ər z̥i̞‿ˈmːɒntl̩ ˈɒpˌt͡si̞ə̯i̞ ‖ d̥ə ˈb̥iːz̥ʋi̞nd̥ | hæt ˈɒːv̥ɛ ˈb̥lɒ \bːz̥ə z̥o v̥eʃ‿tɒz̥ ər hæ‿ˈk͡xønə | ˈɒb̥ər d̥ə ˈmɒː | hæ‿ʔnu̞ d̥ə ˈmɒntl̩ ˈæŋər knɒː ‖ d̥o h \bæ‿ˈt͡su̞nə | ˈɒːv̥ə ˈʒ̥iːnə | ˈi̞mər ˈʋɛːrmər | b̥i̞s tə mɒː | d̥ə ˈmɒntl̩ ˈɒpˌt͡soɡ̥ə hæt  \b‖ d̥o̞ hæ‿tːə ˈb̥iːz̥ˌʋi̞m‿ˈʔmøz̥ə ˈt͡su̞ə̯ɡ̥ɛː | d̥ɒs t͡su̞nː | ˈʃtɛrɣ̥ər z̥ei̯ɡ̥ ˈʋed̥ər ɛːʁ̥ ‖\r\n",
      "\r",
      "\u001b[K\u001b[?1l\u001b>"
     ]
    }
   ],
   "source": [
    "!more sources/Zurich_German_input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment graphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can do is to read these files into Python and segment them with the `segments` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from segments.tokenizer import Tokenizer\n",
    "from segments.cli import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('sources/Brazilian_Portuguese_input.txt') as infile:\n",
    "    text = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u # v ẽ ⁿ t ʊ # n ɔ ɾ t͡ ʃ ɪ̥ # u # s ɔ ʊ̯ # d ʲ i s k u t͡ ʃ i ɐ̃ ʊ̯ # k ʊ̯ a ʊ̯ # d u z # d o ɪ̯ z # ɛ ɾ ɐ # u # m a ɪ̯ s # f ɔ ɾ t͡ ʃ ɪ̥ # | # k ʊ̯ ɐ̃ ⁿ d ʊ # s u s e ˈ d e ʊ̯ # p a ˈ s a ɾ # ũ # v i a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̃ v o ʊ̯ t ʊ # ˈ n ũ m a # k a p ɐ # ‖ # a ʊ̯ # v e l ʊ # p õ ɪ̯ s ɪ # d͡ ʒ ɪ̯ a k o ɾ d ʊ # ɪ̯̃ # k õ m a k e l ɪ # k ɪ # p ɾ i m e ɾ ʊ # k õ s ɪ ˈ g i s̩ # o b ɾ i ˈ g a ɾ # u # v ɪ a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̯ ɐ t͡ ʃ i ˈ ɾ a ɾ # a # k a p ɐ # s e ɾ i ɐ # k õ s̩ d e ˈ ɾ a d u # m a ɪ̯ s # f ɔ ɾ t͡ ʃ ɪ̥ # ‖ # u # v ẽ ⁿ t ʊ # n ɔ ɾ ɪ̥ # k o m e ˈ s o ɐ̯ # s o ˈ p ɾ a ɾ # k õ # ˈ m ũ ɪ̯̃ t a # f u ɾ ɪ̯ ɐ # | # m a s # k ʊ̯ ɐ̃ ⁿ t ʊ # m a ɪ̯ s o p ɾ a v ɐ # m a ɪ̯ z # u # v ɪ a ˈ ʒ ɐ̃ ⁿ t # s ɪ̯ a k õ ʃ e ˈ g a v a # s u ɐ # k a p ɐ̰ # | # a ˈ t ɛ # k ɪ̯ ʊ # v ẽ ⁿ t ʊ # n ɔ ɾ t͡ ʃ ɪ # d ʲ i z i s ˈ t͡ ʃ i ʊ̯ # ‖ # u # s ɔ ʊ̯ # b ɾ i ˈ ʎ o ʊ̯ # t e v ɪ̯ a ˈ s ɪ̃ # d ʲ i # ɣ e k õ ɲ e ˈ s e ɾ # a # s u p e ɾ i o ɾ i d a d ʲ ɪ # d u # s ɔ ʊ̯\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "tokenized_text = t(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The `tokenized_text` contains a default segmentation of the the text. In the `sources` directory we have some hand-vetted gold standard segmented files. We can compare the `tokenized_text` versus the vetted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u # v ẽⁿ t ʊ # n ɔ ɾ t͡ʃ ɪ̥ # u # s ɔ ʊ̯ # dʲ i s k u t͡ʃ i ɐ̃ ʊ̯ # k ʊ̯ a ʊ̯ # d u z # d o ɪ̯ z # ɛ ɾ ɐ # u # m a ɪ̯ s # f ɔ ɾ t͡ʃ ɪ̥ # | # k ʊ̯ ɐ̃ⁿ d ʊ # s u s e ˈd e ʊ̯ # p a ˈs a ɾ # ũ # v i a ʒ ɐ̃ⁿ t͡ʃ ɪ̃ v o ʊ̯ t ʊ # ˈn ũ m a # k a p ɐ # ‖ # a ʊ̯ # v e l ʊ # p õ ɪ̯ s ɪ # d͡ʒ ɪ̯ a k o ɾ d ʊ # ɪ̯̃ # k õ m a k e l ɪ # k ɪ # p ɾ i m e ɾ ʊ # k õ s ɪ ˈg i s̩ # o b ɾ i ˈg a ɾ # u # v ɪ a ʒ ɐ̃ⁿ t͡ʃ ɪ̯ ɐ t͡ʃ i ˈɾ a ɾ # a # k a p ɐ # s e ɾ i ɐ # k õ s̩ d e ˈɾ a d u # m a ɪ̯ s # f ɔ ɾ t͡ʃ ɪ̥ # ‖ # u # v ẽⁿ t ʊ # n ɔ ɾ ɪ̥ # k o m e ˈs o ɐ̯ # s o ˈp ɾ a ɾ # k õ # ˈm ũ ɪ̯̃ t a # f u ɾ ɪ̯ ɐ # | # m a s # k ʊ̯ ɐ̃ⁿ t ʊ # m a ɪ̯ s o p ɾ a v ɐ # m a ɪ̯ z # u # v ɪ a ˈʒ ɐ̃ⁿ t # s ɪ̯ a k õ ʃ e ˈg a v a # s u ɐ # k a p ɐ̰ # | # a ˈt ɛ # k ɪ̯ ʊ # v ẽⁿ t ʊ # n ɔ ɾ t͡ʃ ɪ # dʲ i z i s ˈt͡ʃ i ʊ̯ # ‖ # u # s ɔ ʊ̯ # b ɾ i ˈʎ o ʊ̯ # t e v ɪ̯ a ˈs ɪ̃ # dʲ i # ɣ e k õ ɲ e ˈs e ɾ # a # s u p e ɾ i o ɾ i d a dʲ ɪ # d u # s ɔ ʊ̯\n"
     ]
    }
   ],
   "source": [
    "with open('sources/Brazilian_Portuguese_output.txt') as goldfile:\n",
    "    gold = goldfile.read()\n",
    "    print(gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, something does not look quite right! Can you spot the differences between strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'v ẽ ⁿ t ʊ', 'n ɔ ɾ t͡ ʃ ɪ̥', 'u', 's ɔ ʊ̯', 'd ʲ i s k u t͡ ʃ i ɐ̃ ʊ̯', 'k ʊ̯ a ʊ̯', 'd u z', 'd o ɪ̯ z', 'ɛ ɾ ɐ', 'u', 'm a ɪ̯ s', 'f ɔ ɾ t͡ ʃ ɪ̥', '|', 'k ʊ̯ ɐ̃ ⁿ d ʊ', 's u s e ˈ d e ʊ̯', 'p a ˈ s a ɾ', 'ũ', 'v i a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̃ v o ʊ̯ t ʊ', 'ˈ n ũ m a', 'k a p ɐ', '‖', 'a ʊ̯', 'v e l ʊ', 'p õ ɪ̯ s ɪ', 'd͡ ʒ ɪ̯ a k o ɾ d ʊ', 'ɪ̯̃', 'k õ m a k e l ɪ', 'k ɪ', 'p ɾ i m e ɾ ʊ', 'k õ s ɪ ˈ g i s̩', 'o b ɾ i ˈ g a ɾ', 'u', 'v ɪ a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̯ ɐ t͡ ʃ i ˈ ɾ a ɾ', 'a', 'k a p ɐ', 's e ɾ i ɐ', 'k õ s̩ d e ˈ ɾ a d u', 'm a ɪ̯ s', 'f ɔ ɾ t͡ ʃ ɪ̥', '‖', 'u', 'v ẽ ⁿ t ʊ', 'n ɔ ɾ ɪ̥', 'k o m e ˈ s o ɐ̯', 's o ˈ p ɾ a ɾ', 'k õ', 'ˈ m ũ ɪ̯̃ t a', 'f u ɾ ɪ̯ ɐ', '|', 'm a s', 'k ʊ̯ ɐ̃ ⁿ t ʊ', 'm a ɪ̯ s o p ɾ a v ɐ', 'm a ɪ̯ z', 'u', 'v ɪ a ˈ ʒ ɐ̃ ⁿ t', 's ɪ̯ a k õ ʃ e ˈ g a v a', 's u ɐ', 'k a p ɐ̰', '|', 'a ˈ t ɛ', 'k ɪ̯ ʊ', 'v ẽ ⁿ t ʊ', 'n ɔ ɾ t͡ ʃ ɪ', 'd ʲ i z i s ˈ t͡ ʃ i ʊ̯', '‖', 'u', 's ɔ ʊ̯', 'b ɾ i ˈ ʎ o ʊ̯', 't e v ɪ̯ a ˈ s ɪ̃', 'd ʲ i', 'ɣ e k õ ɲ e ˈ s e ɾ', 'a', 's u p e ɾ i o ɾ i d a d ʲ ɪ', 'd u', 's ɔ ʊ̯']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = tokenized_text.split(' # ')\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'v ẽⁿ t ʊ', 'n ɔ ɾ t͡ʃ ɪ̥', 'u', 's ɔ ʊ̯', 'dʲ i s k u t͡ʃ i ɐ̃ ʊ̯', 'k ʊ̯ a ʊ̯', 'd u z', 'd o ɪ̯ z', 'ɛ ɾ ɐ', 'u', 'm a ɪ̯ s', 'f ɔ ɾ t͡ʃ ɪ̥', '|', 'k ʊ̯ ɐ̃ⁿ d ʊ', 's u s e ˈd e ʊ̯', 'p a ˈs a ɾ', 'ũ', 'v i a ʒ ɐ̃ⁿ t͡ʃ ɪ̃ v o ʊ̯ t ʊ', 'ˈn ũ m a', 'k a p ɐ', '‖', 'a ʊ̯', 'v e l ʊ', 'p õ ɪ̯ s ɪ', 'd͡ʒ ɪ̯ a k o ɾ d ʊ', 'ɪ̯̃', 'k õ m a k e l ɪ', 'k ɪ', 'p ɾ i m e ɾ ʊ', 'k õ s ɪ ˈg i s̩', 'o b ɾ i ˈg a ɾ', 'u', 'v ɪ a ʒ ɐ̃ⁿ t͡ʃ ɪ̯ ɐ t͡ʃ i ˈɾ a ɾ', 'a', 'k a p ɐ', 's e ɾ i ɐ', 'k õ s̩ d e ˈɾ a d u', 'm a ɪ̯ s', 'f ɔ ɾ t͡ʃ ɪ̥', '‖', 'u', 'v ẽⁿ t ʊ', 'n ɔ ɾ ɪ̥', 'k o m e ˈs o ɐ̯', 's o ˈp ɾ a ɾ', 'k õ', 'ˈm ũ ɪ̯̃ t a', 'f u ɾ ɪ̯ ɐ', '|', 'm a s', 'k ʊ̯ ɐ̃ⁿ t ʊ', 'm a ɪ̯ s o p ɾ a v ɐ', 'm a ɪ̯ z', 'u', 'v ɪ a ˈʒ ɐ̃ⁿ t', 's ɪ̯ a k õ ʃ e ˈg a v a', 's u ɐ', 'k a p ɐ̰', '|', 'a ˈt ɛ', 'k ɪ̯ ʊ', 'v ẽⁿ t ʊ', 'n ɔ ɾ t͡ʃ ɪ', 'dʲ i z i s ˈt͡ʃ i ʊ̯', '‖', 'u', 's ɔ ʊ̯', 'b ɾ i ˈʎ o ʊ̯', 't e v ɪ̯ a ˈs ɪ̃', 'dʲ i', 'ɣ e k õ ɲ e ˈs e ɾ', 'a', 's u p e ɾ i o ɾ i d a dʲ ɪ', 'd u', 's ɔ ʊ̯']\n"
     ]
    }
   ],
   "source": [
    "gold_words = gold.split(' # ')\n",
    "print(gold_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's find the delta between the lists of words and identify where the problems are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "\n",
      "+++ \n",
      "\n",
      "@@ -1,76 +1,76 @@\n",
      "\n",
      " u\n",
      "-v ẽ ⁿ t ʊ\n",
      "-n ɔ ɾ t͡ ʃ ɪ̥\n",
      "+v ẽⁿ t ʊ\n",
      "+n ɔ ɾ t͡ʃ ɪ̥\n",
      " u\n",
      " s ɔ ʊ̯\n",
      "-d ʲ i s k u t͡ ʃ i ɐ̃ ʊ̯\n",
      "+dʲ i s k u t͡ʃ i ɐ̃ ʊ̯\n",
      " k ʊ̯ a ʊ̯\n",
      " d u z\n",
      " d o ɪ̯ z\n",
      " ɛ ɾ ɐ\n",
      " u\n",
      " m a ɪ̯ s\n",
      "-f ɔ ɾ t͡ ʃ ɪ̥\n",
      "+f ɔ ɾ t͡ʃ ɪ̥\n",
      " |\n",
      "-k ʊ̯ ɐ̃ ⁿ d ʊ\n",
      "-s u s e ˈ d e ʊ̯\n",
      "-p a ˈ s a ɾ\n",
      "+k ʊ̯ ɐ̃ⁿ d ʊ\n",
      "+s u s e ˈd e ʊ̯\n",
      "+p a ˈs a ɾ\n",
      " ũ\n",
      "-v i a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̃ v o ʊ̯ t ʊ\n",
      "-ˈ n ũ m a\n",
      "+v i a ʒ ɐ̃ⁿ t͡ʃ ɪ̃ v o ʊ̯ t ʊ\n",
      "+ˈn ũ m a\n",
      " k a p ɐ\n",
      " ‖\n",
      " a ʊ̯\n",
      " v e l ʊ\n",
      " p õ ɪ̯ s ɪ\n",
      "-d͡ ʒ ɪ̯ a k o ɾ d ʊ\n",
      "+d͡ʒ ɪ̯ a k o ɾ d ʊ\n",
      " ɪ̯̃\n",
      " k õ m a k e l ɪ\n",
      " k ɪ\n",
      " p ɾ i m e ɾ ʊ\n",
      "-k õ s ɪ ˈ g i s̩\n",
      "-o b ɾ i ˈ g a ɾ\n",
      "+k õ s ɪ ˈg i s̩\n",
      "+o b ɾ i ˈg a ɾ\n",
      " u\n",
      "-v ɪ a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̯ ɐ t͡ ʃ i ˈ ɾ a ɾ\n",
      "+v ɪ a ʒ ɐ̃ⁿ t͡ʃ ɪ̯ ɐ t͡ʃ i ˈɾ a ɾ\n",
      " a\n",
      " k a p ɐ\n",
      " s e ɾ i ɐ\n",
      "-k õ s̩ d e ˈ ɾ a d u\n",
      "+k õ s̩ d e ˈɾ a d u\n",
      " m a ɪ̯ s\n",
      "-f ɔ ɾ t͡ ʃ ɪ̥\n",
      "+f ɔ ɾ t͡ʃ ɪ̥\n",
      " ‖\n",
      " u\n",
      "-v ẽ ⁿ t ʊ\n",
      "+v ẽⁿ t ʊ\n",
      " n ɔ ɾ ɪ̥\n",
      "-k o m e ˈ s o ɐ̯\n",
      "-s o ˈ p ɾ a ɾ\n",
      "+k o m e ˈs o ɐ̯\n",
      "+s o ˈp ɾ a ɾ\n",
      " k õ\n",
      "-ˈ m ũ ɪ̯̃ t a\n",
      "+ˈm ũ ɪ̯̃ t a\n",
      " f u ɾ ɪ̯ ɐ\n",
      " |\n",
      " m a s\n",
      "-k ʊ̯ ɐ̃ ⁿ t ʊ\n",
      "+k ʊ̯ ɐ̃ⁿ t ʊ\n",
      " m a ɪ̯ s o p ɾ a v ɐ\n",
      " m a ɪ̯ z\n",
      " u\n",
      "-v ɪ a ˈ ʒ ɐ̃ ⁿ t\n",
      "-s ɪ̯ a k õ ʃ e ˈ g a v a\n",
      "+v ɪ a ˈʒ ɐ̃ⁿ t\n",
      "+s ɪ̯ a k õ ʃ e ˈg a v a\n",
      " s u ɐ\n",
      " k a p ɐ̰\n",
      " |\n",
      "-a ˈ t ɛ\n",
      "+a ˈt ɛ\n",
      " k ɪ̯ ʊ\n",
      "-v ẽ ⁿ t ʊ\n",
      "-n ɔ ɾ t͡ ʃ ɪ\n",
      "-d ʲ i z i s ˈ t͡ ʃ i ʊ̯\n",
      "+v ẽⁿ t ʊ\n",
      "+n ɔ ɾ t͡ʃ ɪ\n",
      "+dʲ i z i s ˈt͡ʃ i ʊ̯\n",
      " ‖\n",
      " u\n",
      " s ɔ ʊ̯\n",
      "-b ɾ i ˈ ʎ o ʊ̯\n",
      "-t e v ɪ̯ a ˈ s ɪ̃\n",
      "-d ʲ i\n",
      "-ɣ e k õ ɲ e ˈ s e ɾ\n",
      "+b ɾ i ˈʎ o ʊ̯\n",
      "+t e v ɪ̯ a ˈs ɪ̃\n",
      "+dʲ i\n",
      "+ɣ e k õ ɲ e ˈs e ɾ\n",
      " a\n",
      "-s u p e ɾ i o ɾ i d a d ʲ ɪ\n",
      "+s u p e ɾ i o ɾ i d a dʲ ɪ\n",
      " d u\n",
      " s ɔ ʊ̯\n"
     ]
    }
   ],
   "source": [
    "from difflib import unified_diff\n",
    "\n",
    "d = unified_diff(tokenized_words, gold_words)\n",
    "print('\\n'.join(list(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows us which words do not match and it's pretty clear that our default Unicode segmentation (in posic regex terms the grapheme marker \"\\X\") does not deal with some of the Unicode IPA pitfalls discussed in the cookbook. For example, the tie-bar is not attached to both characters; the nasal release <ⁿ> also floats without a base character. Luckily, the `segments` package has a tokenize IPA function meant to deal with IPA text in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u # v ẽ ⁿ t ʊ # n ɔ ɾ t͡ ʃ ɪ̥ # u # s ɔ ʊ̯ # d ʲ i s k u t͡ ʃ i ɐ̃ ʊ̯ # k ʊ̯ a ʊ̯ # d u z # d o ɪ̯ z # ɛ ɾ ɐ # u # m a ɪ̯ s # f ɔ ɾ t͡ ʃ ɪ̥ # | # k ʊ̯ ɐ̃ ⁿ d ʊ # s u s e ˈ d e ʊ̯ # p a ˈ s a ɾ # ũ # v i a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̃ v o ʊ̯ t ʊ # ˈ n ũ m a # k a p ɐ # ‖ # a ʊ̯ # v e l ʊ # p õ ɪ̯ s ɪ # d͡ ʒ ɪ̯ a k o ɾ d ʊ # ɪ̯̃ # k õ m a k e l ɪ # k ɪ # p ɾ i m e ɾ ʊ # k õ s ɪ ˈ g i s̩ # o b ɾ i ˈ g a ɾ # u # v ɪ a ʒ ɐ̃ ⁿ t͡ ʃ ɪ̯ ɐ t͡ ʃ i ˈ ɾ a ɾ # a # k a p ɐ # s e ɾ i ɐ # k õ s̩ d e ˈ ɾ a d u # m a ɪ̯ s # f ɔ ɾ t͡ ʃ ɪ̥ # ‖ # u # v ẽ ⁿ t ʊ # n ɔ ɾ ɪ̥ # k o m e ˈ s o ɐ̯ # s o ˈ p ɾ a ɾ # k õ # ˈ m ũ ɪ̯̃ t a # f u ɾ ɪ̯ ɐ # | # m a s # k ʊ̯ ɐ̃ ⁿ t ʊ # m a ɪ̯ s o p ɾ a v ɐ # m a ɪ̯ z # u # v ɪ a ˈ ʒ ɐ̃ ⁿ t # s ɪ̯ a k õ ʃ e ˈ g a v a # s u ɐ # k a p ɐ̰ # | # a ˈ t ɛ # k ɪ̯ ʊ # v ẽ ⁿ t ʊ # n ɔ ɾ t͡ ʃ ɪ # d ʲ i z i s ˈ t͡ ʃ i ʊ̯ # ‖ # u # s ɔ ʊ̯ # b ɾ i ˈ ʎ o ʊ̯ # t e v ɪ̯ a ˈ s ɪ̃ # d ʲ i # ɣ e k õ ɲ e ˈ s e ɾ # a # s u p e ɾ i o ɾ i d a d ʲ ɪ # d u # s ɔ ʊ̯\n"
     ]
    }
   ],
   "source": [
    "ipa_tokenized_text = t(text, ipa=True)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa_tokenized_text == gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V o i l à !'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t(\"Voilà!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
